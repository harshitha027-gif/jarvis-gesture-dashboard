# ğŸ”· Iron Hologram Lab

> **Gesture-controlled 3D cube interface inspired by Iron Man's holographic displays**

[![Live Demo](https://img.shields.io/badge/Demo-Live-00f3ff?style=for-the-badge)](https://harshitha027-gif.github.io/jarvis-gesture-dashboard/)
[![License](https://img.shields.io/badge/License-MIT-31ffa5?style=for-the-badge)](LICENSE)

![Iron Holo Demo](https://via.placeholder.com/800x400/000/00f3ff?text=Iron+Holo+Demo+GIF)
*Replace with actual demo GIF or screenshot*

---

## âœ¨ Overview

**Iron Holo** brings futuristic gesture control to your browser! Using real-time hand tracking powered by MediaPipe and immersive 3D graphics via Three.js, you can manipulate a neon-glowing holographic cube with intuitive hand gesturesâ€”no mouse, no keyboard, just your hands.

Perfect for exploring computer vision, gesture recognition, and interactive 3D interfaces.

---

## ğŸ¯ Key Features

- **ğŸ–ï¸ Real-time Hand Tracking**: Powered by [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- **ğŸ¨ Stunning 3D Visuals**: Built with [Three.js](https://threejs.org/) featuring neon wireframes and holographic effects
- **ğŸ® Intuitive Gestures**:
  - **Pinch** to grab and move the cube
  - **Twist** your pinched hand to rotate around Z-axis
  - **Peace sign (âœŒï¸)** to toggle rotation mode
  - **Two-hand pinch** for dynamic scaling
- **ğŸ’ Iron Man Aesthetics**: Cyan/neon color scheme with futuristic HUD
- **ğŸ“± Responsive Design**: Works on desktop and mobile browsers with camera access
- **âš¡ Smooth Interactions**: Lerp-based smoothing for fluid motion

---

## ğŸš€ Quick Start

### Prerequisites
- Modern web browser (Chrome, Edge, Firefox, Safari)
- Webcam access
- Good lighting and clear background for optimal hand detection

### Run Locally

1. **Clone the repository**
   ```bash
   git clone https://github.com/harshitha027-gif/jarvis-gesture-dashboard.git
   cd jarvis-gesture-dashboard
   ```

2. **Open the app**
   - Simply open `index.html` in your browser
   - Or use a local server:
     ```bash
     # Python 3
     python -m http.server 8000
     
     # Node.js (with http-server)
     npx http-server
     ```

3. **Grant camera permissions** when prompted

4. **Start gesturing!** ğŸ‰

---

## ğŸ•¹ï¸ Gesture Controls

| Gesture | Action | Description |
|---------|--------|-------------|
| ğŸ‘‰ **Single Pinch** | Move | Pinch thumb + index finger to grab and drag the cube in 3D space |
| ğŸŒ€ **Twist (Pinched)** | Z-Rotation | Rotate your pinched hand to spin the cube around its Z-axis |
| âœŒï¸ **Peace Sign** | Toggle Mode | Switch between **Move** and **Rotate** modes (cooldown: 800ms) |
| ğŸ¯ **Pinch + Drag (Rotate Mode)** | Orbit | Drag to rotate cube around X and Y axes |
| ğŸ‘ **Two-Hand Pinch** | Scale | Pinch with both hands and move them apart/together to scale the cube |
| ğŸ¤š **Open Palm** | Idle | Release pinch to enable idle rotation animation |

---

## ğŸ› ï¸ Technical Details

### Tech Stack

| Technology | Purpose |
|------------|----------|
| **[MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)** | Real-time hand landmark detection (21 keypoints per hand) |
| **[Three.js](https://threejs.org/)** | 3D rendering, lighting, and scene management |
| **Vanilla JavaScript** | Core application logic and gesture recognition |
| **HTML5 Canvas** | Hand skeleton overlay rendering |
| **CSS3** | Holographic UI styling and effects |

### Architecture

```
index.html (645 lines)
â”œâ”€â”€ MediaPipe Integration
â”‚   â”œâ”€â”€ Camera stream capture
â”‚   â”œâ”€â”€ Hand detection (max 2 hands)
â”‚   â””â”€â”€ 21-point landmark tracking
â”œâ”€â”€ Gesture Recognition Engine
â”‚   â”œâ”€â”€ Pinch detection (hysteresis: 0.40/0.52)
â”‚   â”œâ”€â”€ Peace sign detection
â”‚   â””â”€â”€ Hand angle calculation
â”œâ”€â”€ Three.js Scene
â”‚   â”œâ”€â”€ PerspectiveCamera (FOV: 45Â°)
â”‚   â”œâ”€â”€ Neon cube (mesh + wireframe + glow)
â”‚   â”œâ”€â”€ GridHelper (holographic floor)
â”‚   â””â”€â”€ Dynamic lighting
â””â”€â”€ Interaction System
    â”œâ”€â”€ Canvas â†’ 3D world raycasting
    â”œâ”€â”€ Smooth lerp interpolation (Î±=0.35)
    â””â”€â”€ Multi-hand coordination
```

### Core Logic Highlights

**Pinch Detection**
```javascript
// Ratio-based pinch detection with hysteresis
const ratio = distance(thumb, index) / distance(wrist, indexMCP);
if (ratio < 0.40) â†’ Pinch ON
if (ratio > 0.52) â†’ Pinch OFF
```

**3D Projection**
```javascript
// Convert 2D canvas coords to 3D world space
canvasToWorldOnZ(xCanvas, yCanvas, zWorld) {
  const ray = new THREE.Raycaster();
  const plane = new THREE.Plane(new THREE.Vector3(0, 0, 1), -zWorld);
  ray.ray.intersectPlane(plane, worldPoint);
}
```

**Smooth Motion**
```javascript
// Linear interpolation for fluid animations
cubeGroup.position.lerp(targetPosition, 0.35);
cubeGroup.rotation.z = lerpAngle(current, target, 0.35);
```

---

## ğŸ“‚ File Structure

```
jarvis-gesture-dashboard/
â”œâ”€â”€ index.html          # Complete application (HTML + CSS + JS)
â”œâ”€â”€ README.md           # This file
â””â”€â”€ LICENSE             # MIT License (optional)
```

*Single-file architecture for easy deployment and sharing!*

---

## ğŸ¨ Customization

### Change Colors
```javascript
// Line ~300: Cube colors
const meshMat = new THREE.MeshStandardMaterial({
  color: 0x033a4a,        // Dark teal
  emissive: 0x0094ff,     // Cyan glow
});
```

### Adjust Gesture Sensitivity
```javascript
// Line ~50: Pinch thresholds
this.PINCH_ON = 0.40;   // Lower = easier to activate
this.PINCH_OFF = 0.52;  // Higher = less jittery
```

### Modify Smoothing
```javascript
// Line ~51: Interpolation alpha
this.smoothAlpha = 0.35; // 0=instant, 1=very smooth
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit** your changes
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```
4. **Push** to the branch
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Open** a Pull Request

### Ideas for Contributions
- Add more gestures (fist, thumbs up, etc.)
- Support for multiple objects
- Color picker gesture interface
- VR/AR integration
- Mobile touch fallback
- Performance optimizations

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| **Camera not working** | Check browser permissions and use HTTPS (required for camera access) |
| **Hand not detected** | Ensure good lighting and clear background; try adjusting `minDetectionConfidence` |
| **Laggy performance** | Lower `maxNumHands` or reduce `modelComplexity` in line ~80 |
| **Pinch too sensitive** | Increase `PINCH_ON` threshold (line ~50) |

---

## ğŸ“œ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

- **[MediaPipe](https://google.github.io/mediapipe/)** by Google for incredible hand tracking
- **[Three.js](https://threejs.org/)** community for powerful 3D web graphics
- **Iron Man** franchise for the holographic interface inspiration
- All contributors and supporters of this project

---

## ğŸ“¬ Contact

**Created by** [harshitha027-gif](https://github.com/harshitha027-gif)

Feel free to reach out for questions, suggestions, or collaborations!

---

<div align="center">

### â­ Star this repo if you found it useful!

**[ğŸ”— Live Demo](https://harshitha027-gif.github.io/jarvis-gesture-dashboard/)** | **[ğŸ› Report Bug](https://github.com/harshitha027-gif/jarvis-gesture-dashboard/issues)** | **[ğŸ’¡ Request Feature](https://github.com/harshitha027-gif/jarvis-gesture-dashboard/issues)**

*Built with ğŸ’™ and futuristic vibes*

</div>
